{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                text  label  \\\n",
      "0      i just feel really helpless and heavy hearted      4   \n",
      "1  ive enjoyed being able to slouch about relax a...      0   \n",
      "2  i gave up my internship with the dmrg and am f...      4   \n",
      "3                         i dont know i feel so lost      0   \n",
      "4  i am a kindergarten teacher and i am thoroughl...      4   \n",
      "\n",
      "                                   preprocessed_text  \\\n",
      "0                   feel realli helpless heavi heart   \n",
      "1  ive enjoy abl slouch relax unwind frankli need...   \n",
      "2               gave internship dmrg feel distraught   \n",
      "3                                dont know feel lost   \n",
      "4  kindergarten teacher thoroughli weari job take...   \n",
      "\n",
      "                             preprocessed_text_split  \n",
      "0             [feel, realli, helpless, heavi, heart]  \n",
      "1  [ive, enjoy, abl, slouch, relax, unwind, frank...  \n",
      "2         [gave, internship, dmrg, feel, distraught]  \n",
      "3                           [dont, know, feel, lost]  \n",
      "4  [kindergarten, teacher, thoroughli, weari, job...  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from gensim.models import Word2Vec\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "preprocessed_data = pd.read_csv('processed_emotions_dataset_2.csv',index_col=0)\n",
    "preprocessed_data['preprocessed_text_split'] = preprocessed_data['preprocessed_text'].str.split()\n",
    "preprocessed_data = preprocessed_data.dropna()\n",
    "print(preprocessed_data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train Word2Vec model on tokenized text data\n",
    "w2v_model = Word2Vec(sentences=preprocessed_data['preprocessed_text_split'], vector_size=100, window=5, min_count=1, sg=1, seed=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to compute the mean of word vectors for each document\n",
    "def document_vector(words):\n",
    "    # Filter words to only those in the Word2Vec vocabulary\n",
    "    words = [word for word in words if word in w2v_model.wv]\n",
    "    if len(words) == 0:\n",
    "        return np.zeros(100)  # Return a vector of zeros if no words are in the model\n",
    "    return np.mean(w2v_model.wv[words], axis=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply the function to get document vectors\n",
    "preprocessed_data['doc_vector'] = preprocessed_data['preprocessed_text_split'].apply(document_vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data into features and labels\n",
    "X = np.vstack(preprocessed_data['doc_vector'].values)\n",
    "y = preprocessed_data['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "\n",
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, data, labels):\n",
    "        self.data = data\n",
    "        self.labels = labels\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.data[idx], self.labels[idx]\n",
    "\n",
    "dataset_train = CustomDataset(torch.from_numpy(X_train), torch.tensor(y_train.to_list()))\n",
    "\n",
    "dataloader_train = DataLoader(dataset_train, batch_size=16, shuffle=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "class FF_Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.linear_relu_stack = nn.Sequential(\n",
    "            nn.Linear(100, 48),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(48, 12),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(12, 6),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        output = self.linear_relu_stack(x)\n",
    "        return output\n",
    "        \n",
    "\n",
    "feedforward_net = FF_Net()\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "optimizer_ffn = torch.optim.Adam(feedforward_net.parameters(), lr=0.001)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 18468.57271951437\n",
      "Training loss: 15734.032868422568\n",
      "Training loss: 14932.137249425054\n",
      "Training loss: 14445.858680851758\n",
      "Training loss: 14128.484894528985\n",
      "Training loss: 13890.129611760378\n",
      "Training loss: 13727.898867569864\n",
      "Training loss: 13566.754456803203\n",
      "Training loss: 13439.284829229116\n",
      "Training loss: 13353.361218616366\n",
      "Training loss: 13273.478071521968\n",
      "Training loss: 13191.23686401546\n",
      "Training loss: 13125.144766561687\n",
      "Training loss: 13078.516708016396\n",
      "Training loss: 13031.13001601398\n",
      "Training loss: 12975.229168433696\n",
      "Training loss: 12939.79942690581\n",
      "Training loss: 12908.740641139448\n",
      "Training loss: 12876.379453741014\n",
      "Training loss: 12834.73438629508\n",
      "Finished Training\n"
     ]
    }
   ],
   "source": [
    "loss_ffn = []\n",
    "num_epochs_ffn = 20\n",
    "\n",
    "for epoch in range(num_epochs_ffn):  # loop over the dataset multiple times\n",
    "    running_loss_ffn = 0.0\n",
    "\n",
    "    for batch_idx, data in enumerate(dataloader_train):\n",
    "        # get the inputs; data is a list of [inputs, labels]\n",
    "        inputs, labels = data\n",
    "        # print(inputs)\n",
    "        # print(labels)\n",
    "        # zero the parameter gradients\n",
    "        optimizer_ffn.zero_grad()\n",
    "\n",
    "        # forward + backward + optimize\n",
    "        outputs = feedforward_net(inputs)\n",
    "        # print(outputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer_ffn.step()\n",
    "        running_loss_ffn += loss.item()\n",
    "\n",
    "    print(f\"Training loss: {running_loss_ffn}\")\n",
    "    loss_ffn.append(running_loss_ffn)\n",
    "\n",
    "print('Finished Training')\n",
    "\n",
    "torch.save(feedforward_net.state_dict(), 'ffn.pth')  # Saves model file (upload with submission)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.74      0.78     24583\n",
      "           1       0.77      0.86      0.82     28247\n",
      "           2       0.65      0.58      0.61      6877\n",
      "           3       0.68      0.76      0.72     11629\n",
      "           4       0.72      0.66      0.69      9576\n",
      "           5       0.64      0.51      0.57      3133\n",
      "\n",
      "    accuracy                           0.75     84045\n",
      "   macro avg       0.71      0.69      0.70     84045\n",
      "weighted avg       0.75      0.75      0.75     84045\n",
      "\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():    \n",
    "    inputs = torch.from_numpy(X_test)\n",
    "    output = feedforward_net(inputs)\n",
    "    y_pred = output.argmax(1)\n",
    "    y_true = torch.tensor(y_test.to_list())\n",
    "    print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        Actual  Predicted\n",
      "412679       4          5\n",
      "346836       0          0\n",
      "80692        1          1\n",
      "292510       2          1\n",
      "238292       5          5\n"
     ]
    }
   ],
   "source": [
    "# Display the predicted values alongside the actual labels\n",
    "predicted_df = pd.DataFrame({'Actual': y_test, 'Predicted': y_pred})\n",
    "print(predicted_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
