{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "s7IpVqTUU29u"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import re\n",
        "import nltk\n",
        "from sklearn.model_selection import train_test_split\n",
        "from gensim.models import Word2Vec\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "nltk.download('stopwords')\n",
        "from nltk.corpus import stopwords\n",
        "\n",
        "\n",
        "label_mapping = {\n",
        "    0: 'sadness',\n",
        "    1: 'joy',\n",
        "    2: 'love',\n",
        "    3: 'anger',\n",
        "    4: 'fear',\n",
        "    5: 'surprise'\n",
        "}\n",
        "\n",
        "\n",
        "music_recommendations = {\n",
        "    'sadness': ['Melancholic Piano', 'Sad Violin Music'],\n",
        "    'joy': ['Happy Acoustic Guitar', 'Uplifting Piano'],\n",
        "    'love': ['Romantic Piano', 'Love Songs Instrumental'],\n",
        "    'anger': ['Intense Rock Instrumental', 'Heavy Metal Instrumental'],\n",
        "    'fear': ['Dark Cinematic Music', 'Tense Ambient Soundscapes'],\n",
        "    'surprise': ['Energetic Orchestral Music', 'Exciting Electronic Beats'],\n",
        "}\n",
        "\n",
        "\n",
        "data = pd.read_csv('emotions.csv')\n",
        "\n",
        "\n",
        "stop_words = set(stopwords.words('english'))\n",
        "\n",
        "def preprocess_text(text):\n",
        "\n",
        "    text = text.lower()\n",
        "\n",
        "\n",
        "    contractions = {\n",
        "        \"dont\": \"do not\",\n",
        "        \"cant\": \"cannot\",\n",
        "        \"wont\": \"will not\",\n",
        "        \"im\": \"i am\",\n",
        "        \"ive\": \"i have\",\n",
        "        \"id\": \"i would\",\n",
        "        \"youre\": \"you are\",\n",
        "        \"isnt\": \"is not\",\n",
        "        \"wasnt\": \"was not\",\n",
        "        \"shouldnt\": \"should not\",\n",
        "        \"couldnt\": \"could not\",\n",
        "        \"doesnt\": \"does not\",\n",
        "        \"havent\": \"have not\",\n",
        "        \"hasnt\": \"has not\",\n",
        "        \"hadnt\": \"had not\",\n",
        "        \"arent\": \"are not\",\n",
        "        \"werent\": \"were not\",\n",
        "        \"wouldnt\": \"would not\",\n",
        "        \"mustnt\": \"must not\",\n",
        "        \"mightnt\": \"might not\",\n",
        "        \"didnt\": \"did not\",\n",
        "        \"neednt\": \"need not\",\n",
        "        \"oughtnt\": \"ought not\",\n",
        "        \"im\": \"i am\",\n",
        "        \"hes\": \"he is\",\n",
        "        \"shes\": \"she is\",\n",
        "        \"its\": \"it is\",\n",
        "        \"thats\": \"that is\",\n",
        "        \"theres\": \"there is\",\n",
        "        \"whats\": \"what is\",\n",
        "        \"wheres\": \"where is\",\n",
        "        \"whos\": \"who is\",\n",
        "        \"theyre\": \"they are\",\n",
        "        \"weve\": \"we have\",\n",
        "        \"were\": \"we are\",\n",
        "        \"didnt\": \"did not\",\n",
        "        \"doesnt\": \"does not\",\n",
        "        \"dont\": \"do not\",\n",
        "        \"hadnt\": \"had not\",\n",
        "        \"hasnt\": \"has not\",\n",
        "        \"havent\": \"have not\",\n",
        "        \"isnt\": \"is not\",\n",
        "        \"shouldnt\": \"should not\",\n",
        "        \"wasnt\": \"was not\",\n",
        "        \"werent\": \"were not\",\n",
        "        \"wont\": \"will not\",\n",
        "        \"wouldnt\": \"would not\",\n",
        "    }\n",
        "\n",
        "\n",
        "    for contraction, replacement in contractions.items():\n",
        "        text = re.sub(r'\\b' + contraction + r'\\b', replacement, text)\n",
        "\n",
        "\n",
        "    tokens = text.split()\n",
        "    tokens = [re.sub(r'[^a-zA-Z]', '', token) for token in tokens]\n",
        "    tokens = [token for token in tokens if token and token not in stop_words]\n",
        "\n",
        "    return tokens\n",
        "\n",
        "\n",
        "data['processed_text'] = data['text'].apply(preprocess_text)\n",
        "\n",
        "\n",
        "X = data['processed_text']\n",
        "y = data['label']\n",
        "\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, stratify=y, random_state=42)\n",
        "\n",
        "\n",
        "w2v_model = Word2Vec(sentences=X_train, vector_size=100, window=5, min_count=1, workers=4, sg=1)\n",
        "\n",
        "\n",
        "def get_sentence_vector(tokens, model, vector_size=100):\n",
        "    if not tokens:\n",
        "        return np.zeros(vector_size)\n",
        "    valid_vectors = [model.wv[word] for word in tokens if word in model.wv]\n",
        "    if not valid_vectors:\n",
        "        return np.zeros(vector_size)\n",
        "    return np.mean(valid_vectors, axis=0)\n",
        "\n",
        "\n",
        "X_train_vectors = np.array([get_sentence_vector(tokens, w2v_model) for tokens in X_train])\n",
        "X_test_vectors = np.array([get_sentence_vector(tokens, w2v_model) for tokens in X_test])\n",
        "\n",
        "\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "\n",
        "classifier = GaussianNB()\n",
        "classifier.fit(X_train_vectors, y_train)\n",
        "\n",
        "y_pred = classifier.predict(X_test_vectors)\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(f\"Accuracy on test set: {accuracy:.4f}\")\n",
        "\n",
        "\n",
        "def predict_emotion(text):\n",
        "    tokens = preprocess_text(text)\n",
        "    text_vector = get_sentence_vector(tokens, w2v_model)\n",
        "    predicted_label = classifier.predict([text_vector])[0]\n",
        "    predicted_emotion = label_mapping[predicted_label]\n",
        "    return predicted_emotion\n",
        "\n",
        "\n",
        "user_input = input(\"Enter your input: \")\n",
        "detected_emotion = predict_emotion(user_input)\n",
        "print(f\"Detected Emotion: {detected_emotion}\")\n",
        "print(f\"Recommended Music for {detected_emotion}: {music_recommendations.get(detected_emotion, [])}\")\n"
      ]
    }
  ]
}